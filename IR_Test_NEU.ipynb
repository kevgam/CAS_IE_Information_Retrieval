{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kevgam/CAS_IE_Information_Retrieval/blob/main/IR_Test_NEU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vorbereitung des Datensatzes in Spark\n",
        "\n",
        "Unser ursprünglicher Spotify-Datensatz, der über [Kaggle](https://www.kaggle.com/discussions/accomplishments/522912) verfügbar ist, umfasste fast eine Million Datensätze. Aufgrund der Grösse des Datensatzes hatten wir bei der Verarbeitung Performanceprobleme. Daher haben wir den Datensatz zunächst in der Spark-Umgebung der ZHAW vorverarbeitet.\n",
        "\n",
        "\n",
        "Nach dem Standardlogin (inkl. sc.stop() am Schluss) gemäss Anleitung der ZHAW haben wir folgende Schritte ausgeführt:"
      ],
      "metadata": {
        "id": "HXlD0sFkEwOH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installation und Test der Umgebung\n",
        "\n",
        "```python\n",
        "# Installation des notwendigen Pakets\n",
        "sparky.installpackage('langdetect')\n",
        "\n",
        "# Alternativ mit pip\n",
        "pip install langdetect\n",
        "\n",
        "# Test der RDD-Funktionalität\n",
        "import os\n",
        "liste = range(16)\n",
        "rdd = sc.parallelize(liste)\n",
        "print(rdd.collect())\n",
        "print(rdd.glom().collect())\n",
        "\n",
        "# Überprüfen, ob alle Worker die notwendige Software installiert haben\n",
        "if len(list(filter(lambda x: x == [], rdd.glom().collect()))):\n",
        "    raise SystemExit(\"Nicht gut - einige Worker bleiben ohne Softwareinstallation.\")\n",
        "\n",
        "# Testfunktion für Abhängigkeiten\n",
        "def testdep(ignore_arg):\n",
        "    ip = \"160.85.252.66\"  # Beispiel-IP\n",
        "    try:\n",
        "        import lxml\n",
        "    except:\n",
        "        return f\"lxml FAILED! @ {ip}\"\n",
        "    else:\n",
        "        return f\"lxml worked @ {ip}\"\n",
        "\n",
        "# Installation von Abhängigkeiten\n",
        "import subprocess\n",
        "def installdeps(ignore_arg):\n",
        "    p = subprocess.run(\"pip install lxml\", shell=True, stdout=subprocess.PIPE)\n",
        "    return p.stdout.decode()\n",
        "\n",
        "# Ausführen der Installation und Tests\n",
        "rdd.map(installdeps).collect()\n",
        "rdd.map(testdep).collect()\n"
      ],
      "metadata": {
        "id": "aMP-0AZrFpg1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Laden und Verarbeiten der Daten\n",
        "\n",
        "```python\n",
        "# Das File wurde vorgängig in unseren Ordner auf dem Server kopiert\n",
        "filepath = 'songs_with_attributes_and_lyrics.csv'\n",
        "\n",
        "# Laden der CSV-Datei\n",
        "import pandas as pd\n",
        "dfs = pd.read_csv(filepath)\n",
        "\n",
        "# Spark DataFrame laden\n",
        "from pyspark.sql.functions import udf, col\n",
        "from pyspark.sql.types import StringType\n",
        "dfs = spark.read.csv(filepath, header=True, inferSchema=True)\n"
      ],
      "metadata": {
        "id": "jB7ejhFcF9sb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sprache erkennen und Fortschritt protokollieren\n",
        "\n",
        "```python\n",
        "from langdetect import detect\n",
        "\n",
        "# Funktion zur Erkennung der Sprache mit Fortschrittsanzeige\n",
        "def detect_language_with_progress(partition):\n",
        "    total_rows = 0\n",
        "    for row in partition:\n",
        "        try:\n",
        "            lang = detect(row['lyrics'])\n",
        "            yield (row['lyrics'], lang)  # Rückgabe: Originaltext und erkannte Sprache\n",
        "        except Exception:\n",
        "            yield (row['lyrics'], 'unknown')\n",
        "        total_rows += 1\n",
        "        if total_rows % 1000 == 0:  # Fortschritt alle 1000 Zeilen anzeigen\n",
        "            print(f\"Processed {total_rows} rows in this partition\")\n",
        "\n",
        "# RDD-Transformationen anwenden\n",
        "rdd = dfs.rdd.mapPartitions(detect_language_with_progress)\n",
        "\n",
        "# Zurück in ein DataFrame umwandeln\n",
        "schema = StringType()\n",
        "result = rdd.toDF([\"lyrics\", \"lyrics_language\"])\n",
        "\n",
        "# Fortschritt anzeigen\n",
        "result.show()\n"
      ],
      "metadata": {
        "id": "gzp-31kNGS5w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ergebnisse speichern\n",
        "\n",
        "```python\n",
        "# Als Excel-Datei speichern\n",
        "output_path = './processed_songs_with_lyrics.xlsx'\n",
        "dfs.to_excel(output_path, index=False)\n",
        "print(f\"DataFrame saved to: {output_path}\")\n",
        "\n",
        "# Als CSV-Datei speichern\n",
        "csv_output_path = './processed_songs_with_lyrics.csv'\n",
        "dfs.to_csv(csv_output_path, index=False)\n",
        "print(f\"DataFrame saved as CSV file to: {csv_output_path}\")\n"
      ],
      "metadata": {
        "id": "UBobl0MgGgdS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Filterung und Speicherung der englischen Texte\n",
        "\n",
        "```python\n",
        "# Zeilen filtern, in denen die Sprache Englisch ist\n",
        "dfs_en = dfs[dfs['lyrics_language'] == 'en']\n",
        "\n",
        "# Gefilterte Daten als Excel- und CSV-Datei speichern\n",
        "dfs_en.to_excel('./processed_songs_filtered_lyrics_en.xlsx', index=False)\n",
        "dfs_en.to_csv('./processed_songs_filtered_lyrics_en.csv', index=False)\n",
        "\n",
        "print(\"Filtered DataFrame saved as 'filtered_lyrics_en.xlsx' and 'filtered_lyrics_en.csv'\")\n"
      ],
      "metadata": {
        "id": "iqCfQ1OjHDSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cbcj4nRTio8",
        "outputId": "be35a52b-c2f0-4446-8e2b-823d4e4f5f64"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Herausfiltern der Datensätze ohne Albumnamen\n",
        "\n",
        "```python\n",
        "# Installation pandas und openpyxl\n",
        "!pip install pandas openpyxl\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Laden der CSV-Datei\n",
        "file_path = \"/content/drive/MyDrive/ie_information_retrieval_dataset/processed_songs_filtered_lyrics_en.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Filtern aller Zeilen, bei denen 'album_name' nicht NaN ist\n",
        "df_filtered = df.dropna(subset=['album_name'])\n",
        "\n",
        "# Speichern der Datei als CSV\n",
        "output_file_path = '/content/drive/MyDrive/ie_information_retrieval_dataset/processed_songs_filtered_lyrics_with_album_name.csv'\n",
        "df_filtered.to_csv(output_file_path, index=False)\n"
      ],
      "metadata": {
        "id": "FgxQW3nJIJy2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Installation der benötigten Bibliotheken\n",
        "!pip install pandas openpyxl\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "zPm1lOoKlgCj",
        "outputId": "685fa56b-b8c0-4021-dcb1-0fdf5f900ad2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.5)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Lade die Excel-Datei\n",
        "file_path = \"/content/drive/MyDrive/ie_scripting_datasets/Archive/processed_songs_filtered_lyrics_en.xlsx\"\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Entferne die Spalten 'id' und 'album_name'\n",
        "df = df.drop(columns=['id', 'album_name', 'lyrics_language'], errors='ignore')\n",
        "\n",
        "# Entferne alle Datensätze, bei denen 'duration_ms' kleiner als 240000 (4 Minuten) oder größer als 300000 (5 Minuten) ist\n",
        "df = df[(df['duration_ms'] >= 240000) & (df['duration_ms'] <= 300000)]\n",
        "\n",
        "# Entferne Sonderzeichen in den Spalten 'name' und 'artists'\n",
        "# Sonderzeichen inkl. [] werden entfernt\n",
        "df['name'] = df['name'].apply(lambda x: re.sub(r'[^\\w\\s]', '', str(x)))\n",
        "df['artists'] = df['artists'].apply(lambda x: re.sub(r'[^\\w\\s]', '', str(x)))\n",
        "\n",
        "# Filtere alle Zeilen, bei denen 'name' NaN ist\n",
        "df = df.dropna(subset=['name'])\n",
        "\n",
        "# Filtere alle Zeilen, bei denen 'artists' NaN ist\n",
        "df = df.dropna(subset=['artists'])\n",
        "\n",
        "# Entferne Duplikate basierend auf der Kombination aus 'name' und 'artists'\n",
        "df = df.drop_duplicates(subset=['name', 'artists'])\n",
        "\n",
        "# Sicherstellen, dass die Spalte 'lyrics' nur String-Werte enthält\n",
        "df = df[df['lyrics'].apply(lambda x: isinstance(x, str))]\n",
        "\n",
        "# Entferne Zeilenumbrüche innerhalb der 'lyrics' Spalte\n",
        "df['lyrics'] = df['lyrics'].apply(lambda x: str(x).replace('\\n', ' ').replace('\\r', ' ') if isinstance(x, str) else x)\n",
        "\n",
        "# Setze die 'lyrics'-Spalte in Anführungszeichen\n",
        "df['lyrics'] = df['lyrics'].apply(lambda x: f'\"{x}\"' if isinstance(x, str) else x)\n",
        "\n",
        "# Entferne Duplikate basierend auf der Kombination aus 'duration_ms' und 'lyrics'\n",
        "df = df.drop_duplicates(subset=['duration_ms', 'lyrics'])\n",
        "\n",
        "# Speichere die bereinigten Daten als CSV-Datei\n",
        "output_csv_path = '/content/drive/MyDrive/ie_scripting_datasets/Archive/processed_songs_filtered_lyrics_bereinigt.csv'\n",
        "df.to_csv(output_csv_path, index=False)\n",
        "\n",
        "print(f\"Bereinigte CSV-Datei wurde gespeichert unter: {output_csv_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        },
        "id": "i78KzsUZOAbX",
        "outputId": "084ef762-eb49-4dc6-a72b-4369e58dc76d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.5)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-4ec661419f50>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Lade die Excel-Datei\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/ie_scripting_datasets/Archive/processed_songs_filtered_lyrics_en.xlsx\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Entferne die Spalten 'id' und 'album_name'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         io = ExcelFile(\n\u001b[0m\u001b[1;32m    496\u001b[0m             \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1548\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xls\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1549\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1550\u001b[0;31m                 ext = inspect_excel_format(\n\u001b[0m\u001b[1;32m   1551\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1405\u001b[0m         \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPEEK_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"stream is empty\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NLTK-Resourcen herunterladen\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# DataFrame laden\n",
        "df = pd.read_csv('/content/drive/MyDrive/ie_scripting_datasets/Archive/processed_songs_filtered_lyrics_bereinigt.csv')\n",
        "\n",
        "# Sicherstellen, dass die Spalte 'lyrics' keine fehlenden Werte enthält und Strings sind\n",
        "df['lyrics'] = df['lyrics'].fillna('').astype(str)\n",
        "\n",
        "# Funktion zur Textbereinigung\n",
        "def preprocess_text(text):\n",
        "    if not isinstance(text, str):  # Sicherstellen, dass die Eingabe ein String ist\n",
        "        text = str(text)\n",
        "    tokens = word_tokenize(text.lower())  # Tokenisierung & Kleinschreibung\n",
        "    tokens = [word for word in tokens if word.isalpha()]  # Sonderzeichen/Zahlen entfernen\n",
        "    tokens = [word for word in tokens if word not in stopwords.words('english')]  # Stopwörter entfernen\n",
        "    return tokens  # Rückgabe als Liste von Tokens\n",
        "\n",
        "# Bereinigte Tokens in neuer Spalte speichern\n",
        "df['clean_lyrics'] = df['lyrics'].apply(preprocess_text)\n",
        "\n",
        "# Ergebnisse speichern\n",
        "df.to_csv('/content/drive/MyDrive/ie_scripting_datasets/Archive/processed_songs_without_stopwords.csv', index=False)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vept6JiIC-Wy",
        "outputId": "0eaa6362-be6c-4432-c0d9-670a6ca5da48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DataFrame laden\n",
        "df = pd.read_csv('/content/drive/MyDrive/ie_scripting_datasets/Archive/processed_songs_without_stopwords.csv')\n",
        "\n",
        "# Entferne Duplikate in 'clean_lyrics'\n",
        "df = df.drop_duplicates(['clean_lyrics'])\n",
        "\n",
        "# Filtere alle Zeilen, bei denen 'clean_lyrics' NaN ist\n",
        "df = df.dropna(subset=['clean_lyrics'])\n",
        "\n",
        "# Ergebnisse speichern\n",
        "df.to_csv('/content/drive/MyDrive/ie_scripting_datasets/Archive/processed_songs_without_duplicates.csv', index=False)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zCr_4DkMrnHu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 930
        },
        "id": "Tz6So8MpGO0S",
        "outputId": "f80d5b54-1381-472e-afbe-9c8170436bd6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                     name  \\\n",
              "0                             B Movie Box Car Blues  Live   \n",
              "1                                           BabyRock Rock   \n",
              "2                                                    Boom   \n",
              "3       Dearly Departed  Live from Spotify Sxsw 2014 f...   \n",
              "4                                                 E Train   \n",
              "...                                                   ...   \n",
              "142258                                    caress Me Sweet   \n",
              "142259                                  my Heart Ran Away   \n",
              "142260                                          what Baby   \n",
              "142261                                                NaN   \n",
              "142262                                                NaN   \n",
              "\n",
              "                                artists  danceability  energy  key  loudness  \\\n",
              "0       The Blues Brothers Joe Gastwirt         0.606   0.819    9    -8.281   \n",
              "1                             Clorofila         0.692   0.900    8    -7.059   \n",
              "2                        MY FIRST STORY         0.340   0.978    A    -3.785   \n",
              "3                         Shakey Graves         0.561   0.491  7.0    -8.812   \n",
              "4                            Jonny Lang         0.685   0.771    9    -7.671   \n",
              "...                                 ...           ...     ...  ...       ...   \n",
              "142258                      Joy Wellboy         0.536   0.613    5   -10.581   \n",
              "142259                      Joy Wellboy         0.706   0.332    5   -11.015   \n",
              "142260                      Joy Wellboy         0.715   0.544    4    -9.431   \n",
              "142261                      Strangeways         0.411   0.854  6.0    -5.075   \n",
              "142262                         SuperKek         0.456   0.482  8.0   -11.199   \n",
              "\n",
              "         mode  speechiness  acousticness  instrumentalness  liveness  valence  \\\n",
              "0           1       0.0696      0.564000          0.004040    0.9590   0.5040   \n",
              "1           1       0.0279      0.014300          0.432000    0.1090   0.9510   \n",
              "2       Major       0.2090      0.000055          0.000000    0.1990   0.1920   \n",
              "3         1.0       0.1210      0.293000          0.000001    0.6850   0.5780   \n",
              "4           1       0.0296      0.000522          0.002370    0.1750   0.7010   \n",
              "...       ...          ...           ...               ...       ...      ...   \n",
              "142258      0       0.0304      0.086800          0.808000    0.0880   0.7760   \n",
              "142259      1       0.0289      0.366000          0.163000    0.0902   0.4250   \n",
              "142260      0       0.0296      0.028800          0.016300    0.1260   0.3860   \n",
              "142261    0.0       0.0371      0.052900          0.000095    0.3020   0.5280   \n",
              "142262    1.0       0.0504      0.029700          0.000000    0.1110   0.0352   \n",
              "\n",
              "          tempo  duration_ms  \\\n",
              "0        93.307       244400   \n",
              "1       126.038       280107   \n",
              "2       199.918       256000   \n",
              "3        81.138       252798   \n",
              "4       112.807       251000   \n",
              "...         ...          ...   \n",
              "142258  159.001       273895   \n",
              "142259  143.998       271578   \n",
              "142260  122.000       258090   \n",
              "142261   91.092       286280   \n",
              "142262   71.455       281962   \n",
              "\n",
              "                                                   lyrics  \\\n",
              "0       \"Caught a ride into South Dakota  With two gir...   \n",
              "1       \"I can make a choice  and never really have a ...   \n",
              "2       \"Instrumental  All in this whole world now has...   \n",
              "3       \"ooo0o0oo0oo0o...  ooo0o0oo0oo0o...  ooo0o0oo0...   \n",
              "4       \"Take the \"E\" train babe  take the easy train ...   \n",
              "...                                                   ...   \n",
              "142258  \"Squeeze  Caress me sweet and slam the door  I...   \n",
              "142259  \"Looking for it over land and sea  My heart ra...   \n",
              "142260  \"When days are short and nights are long  I fe...   \n",
              "142261  \"You know it's wrong, you know it's right  No ...   \n",
              "142262  \"And all I am is a man  I want the world in my...   \n",
              "\n",
              "                                             clean_lyrics  \n",
              "0       ['caught', 'ride', 'south', 'dakota', 'two', '...  \n",
              "1       ['make', 'choice', 'never', 'really', 'doubt',...  \n",
              "2       ['instrumental', 'whole', 'world', 'already', ...  \n",
              "3       ['well', 'know', 'house', 'haunted', 'yeah', '...  \n",
              "4       ['take', 'e', 'train', 'babe', 'take', 'easy',...  \n",
              "...                                                   ...  \n",
              "142258  ['squeeze', 'caress', 'sweet', 'slam', 'door',...  \n",
              "142259  ['looking', 'land', 'sea', 'heart', 'ran', 'aw...  \n",
              "142260  ['days', 'short', 'nights', 'long', 'feel', 'n...  \n",
              "142261  ['know', 'wrong', 'know', 'right', 'sight', 's...  \n",
              "142262  ['man', 'want', 'world', 'hands', 'hate', 'bea...  \n",
              "\n",
              "[136862 rows x 16 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5629cb71-098a-4dec-8dc3-19be7e8d9769\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>artists</th>\n",
              "      <th>danceability</th>\n",
              "      <th>energy</th>\n",
              "      <th>key</th>\n",
              "      <th>loudness</th>\n",
              "      <th>mode</th>\n",
              "      <th>speechiness</th>\n",
              "      <th>acousticness</th>\n",
              "      <th>instrumentalness</th>\n",
              "      <th>liveness</th>\n",
              "      <th>valence</th>\n",
              "      <th>tempo</th>\n",
              "      <th>duration_ms</th>\n",
              "      <th>lyrics</th>\n",
              "      <th>clean_lyrics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B Movie Box Car Blues  Live</td>\n",
              "      <td>The Blues Brothers Joe Gastwirt</td>\n",
              "      <td>0.606</td>\n",
              "      <td>0.819</td>\n",
              "      <td>9</td>\n",
              "      <td>-8.281</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0696</td>\n",
              "      <td>0.564000</td>\n",
              "      <td>0.004040</td>\n",
              "      <td>0.9590</td>\n",
              "      <td>0.5040</td>\n",
              "      <td>93.307</td>\n",
              "      <td>244400</td>\n",
              "      <td>\"Caught a ride into South Dakota  With two gir...</td>\n",
              "      <td>['caught', 'ride', 'south', 'dakota', 'two', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BabyRock Rock</td>\n",
              "      <td>Clorofila</td>\n",
              "      <td>0.692</td>\n",
              "      <td>0.900</td>\n",
              "      <td>8</td>\n",
              "      <td>-7.059</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0279</td>\n",
              "      <td>0.014300</td>\n",
              "      <td>0.432000</td>\n",
              "      <td>0.1090</td>\n",
              "      <td>0.9510</td>\n",
              "      <td>126.038</td>\n",
              "      <td>280107</td>\n",
              "      <td>\"I can make a choice  and never really have a ...</td>\n",
              "      <td>['make', 'choice', 'never', 'really', 'doubt',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Boom</td>\n",
              "      <td>MY FIRST STORY</td>\n",
              "      <td>0.340</td>\n",
              "      <td>0.978</td>\n",
              "      <td>A</td>\n",
              "      <td>-3.785</td>\n",
              "      <td>Major</td>\n",
              "      <td>0.2090</td>\n",
              "      <td>0.000055</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.1990</td>\n",
              "      <td>0.1920</td>\n",
              "      <td>199.918</td>\n",
              "      <td>256000</td>\n",
              "      <td>\"Instrumental  All in this whole world now has...</td>\n",
              "      <td>['instrumental', 'whole', 'world', 'already', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Dearly Departed  Live from Spotify Sxsw 2014 f...</td>\n",
              "      <td>Shakey Graves</td>\n",
              "      <td>0.561</td>\n",
              "      <td>0.491</td>\n",
              "      <td>7.0</td>\n",
              "      <td>-8.812</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.1210</td>\n",
              "      <td>0.293000</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>0.6850</td>\n",
              "      <td>0.5780</td>\n",
              "      <td>81.138</td>\n",
              "      <td>252798</td>\n",
              "      <td>\"ooo0o0oo0oo0o...  ooo0o0oo0oo0o...  ooo0o0oo0...</td>\n",
              "      <td>['well', 'know', 'house', 'haunted', 'yeah', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>E Train</td>\n",
              "      <td>Jonny Lang</td>\n",
              "      <td>0.685</td>\n",
              "      <td>0.771</td>\n",
              "      <td>9</td>\n",
              "      <td>-7.671</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0296</td>\n",
              "      <td>0.000522</td>\n",
              "      <td>0.002370</td>\n",
              "      <td>0.1750</td>\n",
              "      <td>0.7010</td>\n",
              "      <td>112.807</td>\n",
              "      <td>251000</td>\n",
              "      <td>\"Take the \"E\" train babe  take the easy train ...</td>\n",
              "      <td>['take', 'e', 'train', 'babe', 'take', 'easy',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142258</th>\n",
              "      <td>caress Me Sweet</td>\n",
              "      <td>Joy Wellboy</td>\n",
              "      <td>0.536</td>\n",
              "      <td>0.613</td>\n",
              "      <td>5</td>\n",
              "      <td>-10.581</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0304</td>\n",
              "      <td>0.086800</td>\n",
              "      <td>0.808000</td>\n",
              "      <td>0.0880</td>\n",
              "      <td>0.7760</td>\n",
              "      <td>159.001</td>\n",
              "      <td>273895</td>\n",
              "      <td>\"Squeeze  Caress me sweet and slam the door  I...</td>\n",
              "      <td>['squeeze', 'caress', 'sweet', 'slam', 'door',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142259</th>\n",
              "      <td>my Heart Ran Away</td>\n",
              "      <td>Joy Wellboy</td>\n",
              "      <td>0.706</td>\n",
              "      <td>0.332</td>\n",
              "      <td>5</td>\n",
              "      <td>-11.015</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0289</td>\n",
              "      <td>0.366000</td>\n",
              "      <td>0.163000</td>\n",
              "      <td>0.0902</td>\n",
              "      <td>0.4250</td>\n",
              "      <td>143.998</td>\n",
              "      <td>271578</td>\n",
              "      <td>\"Looking for it over land and sea  My heart ra...</td>\n",
              "      <td>['looking', 'land', 'sea', 'heart', 'ran', 'aw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142260</th>\n",
              "      <td>what Baby</td>\n",
              "      <td>Joy Wellboy</td>\n",
              "      <td>0.715</td>\n",
              "      <td>0.544</td>\n",
              "      <td>4</td>\n",
              "      <td>-9.431</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0296</td>\n",
              "      <td>0.028800</td>\n",
              "      <td>0.016300</td>\n",
              "      <td>0.1260</td>\n",
              "      <td>0.3860</td>\n",
              "      <td>122.000</td>\n",
              "      <td>258090</td>\n",
              "      <td>\"When days are short and nights are long  I fe...</td>\n",
              "      <td>['days', 'short', 'nights', 'long', 'feel', 'n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142261</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Strangeways</td>\n",
              "      <td>0.411</td>\n",
              "      <td>0.854</td>\n",
              "      <td>6.0</td>\n",
              "      <td>-5.075</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0371</td>\n",
              "      <td>0.052900</td>\n",
              "      <td>0.000095</td>\n",
              "      <td>0.3020</td>\n",
              "      <td>0.5280</td>\n",
              "      <td>91.092</td>\n",
              "      <td>286280</td>\n",
              "      <td>\"You know it's wrong, you know it's right  No ...</td>\n",
              "      <td>['know', 'wrong', 'know', 'right', 'sight', 's...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142262</th>\n",
              "      <td>NaN</td>\n",
              "      <td>SuperKek</td>\n",
              "      <td>0.456</td>\n",
              "      <td>0.482</td>\n",
              "      <td>8.0</td>\n",
              "      <td>-11.199</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0504</td>\n",
              "      <td>0.029700</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.1110</td>\n",
              "      <td>0.0352</td>\n",
              "      <td>71.455</td>\n",
              "      <td>281962</td>\n",
              "      <td>\"And all I am is a man  I want the world in my...</td>\n",
              "      <td>['man', 'want', 'world', 'hands', 'hate', 'bea...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>136862 rows × 16 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5629cb71-098a-4dec-8dc3-19be7e8d9769')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5629cb71-098a-4dec-8dc3-19be7e8d9769 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5629cb71-098a-4dec-8dc3-19be7e8d9769');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-59dcbc4a-658f-426a-9784-597a679e7c44\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-59dcbc4a-658f-426a-9784-597a679e7c44')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-59dcbc4a-658f-426a-9784-597a679e7c44 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_09d87664-8407-49a9-8f59-a45fa11d5abc\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_09d87664-8407-49a9-8f59-a45fa11d5abc button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Klassifikation nach Emotionen\n",
        "\n",
        "# Das NRC Emotion Lexicon ist ein von der National Research Council Canada (NRC) entwickeltes Lexikon,\n",
        "# das englische Wörter und ihre Assoziationen mit acht grundlegenden Emotionen\n",
        "# (Wut, Angst, Erwartung, Vertrauen, Überraschung, Traurigkeit, Freude und Ekel)\n",
        "# sowie zwei Sentiments (negativ und positiv) enthält\n",
        "\n",
        "# https://saifmohammad.com/WebPages/NRC-Emotion-Lexicon.htm\n",
        "\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "# Lade die Eingabedatei\n",
        "data = pd.read_csv('/content/drive/MyDrive/ie_scripting_datasets/Archive/processed_songs_without_duplicates.csv')\n",
        "\n",
        "# Lade das NRC Emotion Lexikon\n",
        "nrc_lexicon = pd.read_csv('/content/drive/MyDrive/ie_scripting_datasets/Archive/NRC-Emotion-Lexicon-Wordlevel-v0.92.txt', sep='\\t', header=None, names=['word', 'emotion', 'value'])  # Enthält Wörter und zugehörige Emotionen\n",
        "# Nur relevante Einträge\n",
        "nrc_lexicon = nrc_lexicon[nrc_lexicon['value'] == 1]\n",
        "\n",
        "# Zuordnung der Emotionen zu den Kategorien\n",
        "emotion_categories = {\n",
        "    'anger': ['anger'],\n",
        "    'fear': ['fear'],\n",
        "    'anticipation': ['anticipation'],\n",
        "    'trust': ['trust'],\n",
        "    'surprise': ['surprise'],\n",
        "    'sadness': ['sadness'],\n",
        "    'joy': ['joy'],\n",
        "    'disgust': ['disgust'],\n",
        "    'negative': ['negative'],\n",
        "    'positive': ['positive']\n",
        "}\n",
        "\n",
        "# Funktion zur Emotionenzählung und Kategorisierung\n",
        "def get_emotions_and_category(tokens, lexicon, emotion_categories):\n",
        "    \"\"\"\n",
        "    Zählt Emotionen und kategorisiert sie basierend auf Tokens und NRC-Emotion-Lexikon.\n",
        "\n",
        "    Args:\n",
        "        tokens (list): Liste von Tokens aus der Spalte `clean_lyrics`.\n",
        "        lexicon (DataFrame): Das NRC-Emotion-Lexikon.\n",
        "        emotion_categories (dict): Mapping der Emotionen zu Kategorien.\n",
        "\n",
        "    Returns:\n",
        "        tuple: emotion_counts (Counter), category_counts (dict), sentiment (str)\n",
        "    \"\"\"\n",
        "    if isinstance(tokens, str):  # Wenn Tokens als String vorliegen\n",
        "        tokens = tokens.split()  # Zerlege den String in Tokens\n",
        "\n",
        "    # Zähle Emotionen für die Tokens, die im Lexikon vorkommen\n",
        "    emotions = lexicon[lexicon['word'].isin(tokens)]['emotion'].values\n",
        "    emotion_counts = Counter(emotions)\n",
        "\n",
        "    # Kategorisierung der Emotionen\n",
        "    category_counts = {category: sum(emotion_counts[emotion] for emotion in emotions_list)\n",
        "                       for category, emotions_list in emotion_categories.items()}\n",
        "\n",
        "    # Klassifikation in Positiv oder Negativ\n",
        "    is_positive = category_counts['joy'] > category_counts['sadness']\n",
        "    sentiment = 'positive' if is_positive else 'negative'\n",
        "\n",
        "    return emotion_counts, category_counts, sentiment\n",
        "\n",
        "# Anwenden der Funktion auf die Spalte `clean_lyrics`\n",
        "data['emotion_counts'], data['category_counts'], data['sentiment'] = zip(*data['clean_lyrics'].apply(lambda x: get_emotions_and_category(str(x), nrc_lexicon, emotion_categories)))\n",
        "\n",
        "# Optional: Ergebnisse zur Übersicht ausgeben\n",
        "print(data[['clean_lyrics', 'emotion_counts', 'category_counts', 'sentiment']].head())\n",
        "\n",
        "\n",
        "# Ergebnis speichern\n",
        "output_csv_path = '/content/drive/MyDrive/ie_scripting_datasets/Archive/processed_songs_with_emotions.csv'\n",
        "data.to_csv(output_csv_path, index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWnkEdg-HUKZ",
        "outputId": "4edf65fb-19b5-41fa-ad87-b2823a482328"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                        clean_lyrics emotion_counts  \\\n",
            "0  ['caught', 'ride', 'south', 'dakota', 'two', '...             {}   \n",
            "1  ['make', 'choice', 'never', 'really', 'doubt',...             {}   \n",
            "2  ['instrumental', 'whole', 'world', 'already', ...             {}   \n",
            "3  ['well', 'know', 'house', 'haunted', 'yeah', '...             {}   \n",
            "4  ['take', 'e', 'train', 'babe', 'take', 'easy',...             {}   \n",
            "\n",
            "                                     category_counts sentiment  \n",
            "0  {'anger': 0, 'fear': 0, 'anticipation': 0, 'tr...  negative  \n",
            "1  {'anger': 0, 'fear': 0, 'anticipation': 0, 'tr...  negative  \n",
            "2  {'anger': 0, 'fear': 0, 'anticipation': 0, 'tr...  negative  \n",
            "3  {'anger': 0, 'fear': 0, 'anticipation': 0, 'tr...  negative  \n",
            "4  {'anger': 0, 'fear': 0, 'anticipation': 0, 'tr...  negative  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import pandas as pd\n",
        "\n",
        "# Lade die Eingabedatei\n",
        "data = pd.read_csv('/content/drive/MyDrive/ie_scripting_datasets/Archive/processed_songs_without_duplicates.csv')\n",
        "\n",
        "# Überprüfen, ob die Spalte `clean_lyrics` korrekt ist\n",
        "if 'clean_lyrics' not in data.columns:\n",
        "    raise ValueError(\"Die Spalte 'clean_lyrics' ist nicht in den Daten enthalten. Bitte prüfen Sie die Eingabedatei.\")\n",
        "\n",
        "# Lade das NRC Emotion Lexikon\n",
        "nrc_lexicon = pd.read_csv(\n",
        "    '/content/drive/MyDrive/ie_scripting_datasets/Archive/NRC-Emotion-Lexicon-Wordlevel-v0.92.txt',\n",
        "    sep='\\t',\n",
        "    header=None,\n",
        "    names=['word', 'emotion', 'value']\n",
        ")\n",
        "\n",
        "# Nur relevante Einträge behalten\n",
        "nrc_lexicon = nrc_lexicon[nrc_lexicon['value'] == 1]\n",
        "\n",
        "# Zuordnung der Emotionen zu den Kategorien\n",
        "emotion_categories = {\n",
        "    'anger': ['anger'],\n",
        "    'fear': ['fear'],\n",
        "    'anticipation': ['anticipation'],\n",
        "    'trust': ['trust'],\n",
        "    'surprise': ['surprise'],\n",
        "    'sadness': ['sadness'],\n",
        "    'joy': ['joy'],\n",
        "    'disgust': ['disgust']\n",
        "}\n",
        "\n",
        "# Funktion zur Emotionenzählung und Kategorisierung\n",
        "def get_emotions_and_category(tokens, lexicon, emotion_categories):\n",
        "    \"\"\"\n",
        "    Zählt Emotionen und kategorisiert sie basierend auf Tokens und NRC-Emotion-Lexikon.\n",
        "\n",
        "    Args:\n",
        "        tokens (str or list): Tokens oder Text aus der Spalte `clean_lyrics`.\n",
        "        lexicon (DataFrame): Das NRC-Emotion-Lexikon.\n",
        "        emotion_categories (dict): Mapping der Emotionen zu Kategorien.\n",
        "\n",
        "    Returns:\n",
        "        tuple: emotion_counts (Counter), category_counts (dict), sentiment (str)\n",
        "    \"\"\"\n",
        "    if isinstance(tokens, str):  # Wenn Tokens als String vorliegen\n",
        "        tokens = tokens.split()  # Zerlege den String in Tokens\n",
        "\n",
        "    # Zähle Emotionen für die Tokens, die im Lexikon vorkommen\n",
        "    emotions = lexicon[lexicon['word'].isin(tokens)]['emotion'].values\n",
        "    emotion_counts = Counter(emotions)\n",
        "\n",
        "    # Kategorisierung der Emotionen\n",
        "    category_counts = {\n",
        "        category: sum(emotion_counts[emotion] for emotion in emotions_list)\n",
        "        for category, emotions_list in emotion_categories.items()\n",
        "    }\n",
        "\n",
        "    # Klassifikation in Positiv oder Negativ\n",
        "    is_positive = category_counts.get('joy', 0) > category_counts.get('sadness', 0)\n",
        "    sentiment = 'positive' if is_positive else 'negative'\n",
        "\n",
        "    return emotion_counts, category_counts, sentiment\n",
        "\n",
        "# Anwenden der Funktion auf die Spalte `clean_lyrics`\n",
        "results = data['clean_lyrics'].apply(\n",
        "    lambda x: get_emotions_and_category(str(x), nrc_lexicon, emotion_categories)\n",
        ")\n",
        "\n",
        "# Ergebnisse extrahieren und zu Spalten hinzufügen\n",
        "data['emotion_counts'] = results.map(lambda x: x[0])\n",
        "data['category_counts'] = results.map(lambda x: x[1])\n",
        "data['sentiment'] = results.map(lambda x: x[2])\n",
        "\n",
        "# Optional: Ergebnisse zur Übersicht ausgeben\n",
        "print(data[['clean_lyrics', 'emotion_counts', 'category_counts', 'sentiment']].head())\n",
        "\n",
        "# Ergebnis speichern\n",
        "output_csv_path = '/content/drive/MyDrive/ie_scripting_datasets/Archive/processed_songs_with_emotions.csv'\n",
        "data.to_csv(output_csv_path, index=False)\n",
        "print(f\"Ergebnis gespeichert: {output_csv_path}\")\n"
      ],
      "metadata": {
        "id": "Qhl9wZg2o_xn",
        "outputId": "56c129cf-a192-4367-952b-2b58349a4772",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                        clean_lyrics emotion_counts  \\\n",
            "0  ['caught', 'ride', 'south', 'dakota', 'two', '...             {}   \n",
            "1  ['make', 'choice', 'never', 'really', 'doubt',...             {}   \n",
            "2  ['instrumental', 'whole', 'world', 'already', ...             {}   \n",
            "3  ['well', 'know', 'house', 'haunted', 'yeah', '...             {}   \n",
            "4  ['take', 'e', 'train', 'babe', 'take', 'easy',...             {}   \n",
            "\n",
            "                                     category_counts sentiment  \n",
            "0  {'anger': 0, 'fear': 0, 'anticipation': 0, 'tr...  negative  \n",
            "1  {'anger': 0, 'fear': 0, 'anticipation': 0, 'tr...  negative  \n",
            "2  {'anger': 0, 'fear': 0, 'anticipation': 0, 'tr...  negative  \n",
            "3  {'anger': 0, 'fear': 0, 'anticipation': 0, 'tr...  negative  \n",
            "4  {'anger': 0, 'fear': 0, 'anticipation': 0, 'tr...  negative  \n",
            "Ergebnis gespeichert: /content/drive/MyDrive/ie_scripting_datasets/Archive/processed_songs_with_emotions.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import ast\n",
        "\n",
        "# Lade die Eingabedatei\n",
        "data = pd.read_csv('/content/drive/MyDrive/ie_scripting_datasets/Archive/processed_songs_without_duplicates.csv')\n",
        "\n",
        "# Lade das NRC Emotion Lexikon\n",
        "nrc_lexicon = pd.read_csv(\n",
        "    '/content/drive/MyDrive/ie_scripting_datasets/Archive/NRC-Emotion-Lexicon-Wordlevel-v0.92.txt',\n",
        "    sep='\\t',\n",
        "    header=None,\n",
        "    names=['word', 'emotion', 'value']\n",
        ")\n",
        "\n",
        "# Nur relevante Einträge behalten\n",
        "nrc_lexicon = nrc_lexicon[nrc_lexicon['value'] == 1]\n",
        "\n",
        "# Zuordnung der Emotionen zu den Kategorien\n",
        "emotion_categories = {\n",
        "    'anger': ['anger'],\n",
        "    'fear': ['fear'],\n",
        "    'anticipation': ['anticipation'],\n",
        "    'trust': ['trust'],\n",
        "    'surprise': ['surprise'],\n",
        "    'sadness': ['sadness'],\n",
        "    'joy': ['joy'],\n",
        "    'disgust': ['disgust']\n",
        "}\n",
        "\n",
        "# Funktion zur Emotionenzählung und Kategorisierung\n",
        "def get_emotions_and_category(tokens, lexicon, emotion_categories):\n",
        "    \"\"\"\n",
        "    Zählt Emotionen und kategorisiert sie basierend auf Tokens und NRC-Emotion-Lexikon.\n",
        "\n",
        "    Args:\n",
        "        tokens (str or list): Tokens aus der Spalte `clean_lyrics`.\n",
        "        lexicon (DataFrame): Das NRC-Emotion-Lexikon.\n",
        "        emotion_categories (dict): Mapping der Emotionen zu Kategorien.\n",
        "\n",
        "    Returns:\n",
        "        tuple: emotion_counts (Counter), category_counts (dict), sentiment (str)\n",
        "    \"\"\"\n",
        "    if isinstance(tokens, str):  # Wenn Tokens als String vorliegen\n",
        "        tokens = ast.literal_eval(tokens)  # Konvertiere den String in eine echte Liste\n",
        "\n",
        "    # Zähle Emotionen für die Tokens, die im Lexikon vorkommen\n",
        "    emotions = lexicon[lexicon['word'].isin(tokens)]['emotion'].values\n",
        "    emotion_counts = Counter(emotions)\n",
        "\n",
        "    # Kategorisierung der Emotionen\n",
        "    category_counts = {\n",
        "        category: sum(emotion_counts[emotion] for emotion in emotions_list)\n",
        "        for category, emotions_list in emotion_categories.items()\n",
        "    }\n",
        "\n",
        "    # Klassifikation in Positiv oder Negativ\n",
        "    is_positive = category_counts.get('joy', 0) > category_counts.get('sadness', 0)\n",
        "    sentiment = 'positive' if is_positive else 'negative'\n",
        "\n",
        "    return emotion_counts, category_counts, sentiment\n",
        "\n",
        "# Anwenden der Funktion auf die Spalte `clean_lyrics`\n",
        "results = data['clean_lyrics'].apply(\n",
        "    lambda x: get_emotions_and_category(x, nrc_lexicon, emotion_categories)\n",
        ")\n",
        "\n",
        "# Ergebnisse extrahieren und zu Spalten hinzufügen\n",
        "data['emotion_counts'] = results.map(lambda x: x[0])\n",
        "data['category_counts'] = results.map(lambda x: x[1])\n",
        "data['sentiment'] = results.map(lambda x: x[2])\n",
        "\n",
        "# Optional: Ergebnisse zur Übersicht ausgeben\n",
        "print(data[['clean_lyrics', 'emotion_counts', 'category_counts', 'sentiment']].head())\n",
        "\n",
        "# Ergebnis speichern\n",
        "output_csv_path = '/content/drive/MyDrive/ie_scripting_datasets/Archive/processed_songs_with_emotions.csv'\n",
        "data.to_csv(output_csv_path, index=False)\n",
        "print(f\"Ergebnis gespeichert: {output_csv_path}\")\n"
      ],
      "metadata": {
        "id": "oPaVZ1KbuEmx",
        "outputId": "e8c58713-7a4b-4373-886f-bd9db3a42671",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                        clean_lyrics  \\\n",
            "0  ['caught', 'ride', 'south', 'dakota', 'two', '...   \n",
            "1  ['make', 'choice', 'never', 'really', 'doubt',...   \n",
            "2  ['instrumental', 'whole', 'world', 'already', ...   \n",
            "3  ['well', 'know', 'house', 'haunted', 'yeah', '...   \n",
            "4  ['take', 'e', 'train', 'babe', 'take', 'easy',...   \n",
            "\n",
            "                                      emotion_counts  \\\n",
            "0  {'sadness': 2, 'joy': 2, 'positive': 4, 'negat...   \n",
            "1  {'positive': 5, 'anticipation': 4, 'fear': 5, ...   \n",
            "2  {'joy': 4, 'positive': 9, 'trust': 7, 'anger':...   \n",
            "3  {'anticipation': 3, 'joy': 3, 'positive': 5, '...   \n",
            "4  {'joy': 2, 'positive': 5, 'anticipation': 2, '...   \n",
            "\n",
            "                                     category_counts sentiment  \n",
            "0  {'anger': 0, 'fear': 0, 'anticipation': 0, 'tr...  negative  \n",
            "1  {'anger': 3, 'fear': 5, 'anticipation': 4, 'tr...  negative  \n",
            "2  {'anger': 1, 'fear': 3, 'anticipation': 6, 'tr...  positive  \n",
            "3  {'anger': 2, 'fear': 7, 'anticipation': 3, 'tr...  negative  \n",
            "4  {'anger': 0, 'fear': 0, 'anticipation': 2, 'tr...  positive  \n",
            "Ergebnis gespeichert: /content/drive/MyDrive/ie_scripting_datasets/Archive/processed_songs_with_emotions.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import ast\n",
        "\n",
        "# Lade die Eingabedatei\n",
        "data = pd.read_csv('/content/drive/MyDrive/ie_scripting_datasets/Archive/processed_songs_without_duplicates.csv')\n",
        "\n",
        "# Lade das NRC Emotion Lexikon\n",
        "nrc_lexicon = pd.read_csv(\n",
        "    '/content/drive/MyDrive/ie_scripting_datasets/Archive/NRC-Emotion-Lexicon-Wordlevel-v0.92.txt',\n",
        "    sep='\\t',\n",
        "    header=None,\n",
        "    names=['word', 'emotion', 'value']\n",
        ")\n",
        "\n",
        "# Nur relevante Einträge behalten\n",
        "nrc_lexicon = nrc_lexicon[nrc_lexicon['value'] == 1]\n",
        "\n",
        "# Zuordnung der Emotionen zu den Kategorien\n",
        "emotion_categories = {\n",
        "    'anger': ['anger'],\n",
        "    'fear': ['fear'],\n",
        "    'anticipation': ['anticipation'],\n",
        "    'trust': ['trust'],\n",
        "    'surprise': ['surprise'],\n",
        "    'sadness': ['sadness'],\n",
        "    'joy': ['joy'],\n",
        "    'disgust': ['disgust']\n",
        "}\n",
        "\n",
        "# Berechnung der Sentiment-Ratio\n",
        "def calculate_sentiment_ratio(row):\n",
        "    category_counts = eval(row['category_counts'])  # String in Dictionary umwandeln\n",
        "    positive = category_counts.get('positive', 0)\n",
        "    negative = category_counts.get('negative', 0)\n",
        "    if positive + negative > 0:\n",
        "        return positive / (positive + negative)\n",
        "    return 0  # Verhindert Division durch Null\n",
        "\n",
        "# Spalte hinzufügen\n",
        "data['sentiment_ratio'] = data.apply(calculate_sentiment_ratio, axis=1)\n",
        "\n",
        "\n",
        "\n",
        "# Funktion zur Emotionenzählung und Kategorisierung\n",
        "def get_emotions_and_category(tokens, lexicon, emotion_categories):\n",
        "    if isinstance(tokens, str):  # Wenn Tokens als String vorliegen\n",
        "        tokens = ast.literal_eval(tokens)  # Konvertiere den String in eine echte Liste\n",
        "\n",
        "    # Zähle Emotionen für die Tokens, die im Lexikon vorkommen\n",
        "    emotions = lexicon[lexicon['word'].isin(tokens)]['emotion'].values\n",
        "    emotion_counts = Counter(emotions)\n",
        "\n",
        "    # Kategorisierung der Emotionen\n",
        "    category_counts = {\n",
        "        category: sum(emotion_counts[emotion] for emotion in emotions_list)\n",
        "        for category, emotions_list in emotion_categories.items()\n",
        "    }\n",
        "\n",
        "    # Klassifikation in Positiv oder Negativ\n",
        "    is_positive = category_counts.get('joy', 0) > category_counts.get('sadness', 0)\n",
        "    sentiment = 'positive' if is_positive else 'negative'\n",
        "\n",
        "    return emotion_counts, category_counts, sentiment\n",
        "\n",
        "# Anwenden der Funktion auf die Spalte `clean_lyrics`\n",
        "results = data['clean_lyrics'].apply(\n",
        "    lambda x: get_emotions_and_category(x, nrc_lexicon, emotion_categories)\n",
        ")\n",
        "\n",
        "# Ergebnisse extrahieren und zu Spalten hinzufügen\n",
        "data['emotion_counts'] = results.map(lambda x: x[0])\n",
        "data['category_counts'] = results.map(lambda x: x[1])\n",
        "data['sentiment'] = results.map(lambda x: x[2])\n",
        "\n",
        "# Funktion zur primären Emotionserkennung\n",
        "def determine_primary_emotion(category_counts):\n",
        "    \"\"\"\n",
        "    Bestimmt die primäre Emotion basierend auf den Kategoriezählungen.\n",
        "\n",
        "    Args:\n",
        "        category_counts (dict): Dictionary mit Emotionenkategorien und deren Zählungen.\n",
        "\n",
        "    Returns:\n",
        "        str: Primäre Emotion (Kategorie) oder 'neutral', falls keine Emotion dominiert.\n",
        "    \"\"\"\n",
        "    if not category_counts:\n",
        "        return 'neutral'\n",
        "    # Finde die Kategorie mit der höchsten Zählung\n",
        "    primary_emotion = max(category_counts, key=category_counts.get)\n",
        "    # Wenn alle Werte 0 sind, return 'neutral'\n",
        "    if category_counts[primary_emotion] == 0:\n",
        "        return 'neutral'\n",
        "    return primary_emotion\n",
        "\n",
        "# Primäre Emotion bestimmen und als neue Spalte hinzufügen\n",
        "data['primary_emotion'] = data['category_counts'].apply(determine_primary_emotion)\n",
        "\n",
        "# Songs nach Emotionen aufteilen\n",
        "emotion_groups = {\n",
        "    emotion: data[data['primary_emotion'] == emotion]\n",
        "    for emotion in emotion_categories.keys()\n",
        "}\n",
        "\n",
        "# Ergebnisse speichern (optional)\n",
        "for emotion, group in emotion_groups.items():\n",
        "    group.to_csv(f'/content/drive/MyDrive/ie_scripting_datasets/Archive/songs_emotion.csv', index=False)\n",
        "\n",
        "# Übersicht ausgeben\n",
        "print(data[['clean_lyrics', 'category_counts', 'primary_emotion']].head())\n",
        "print(f\"Songs wurden nach Emotionen aufgeteilt und gespeichert.\")\n",
        "\n",
        "# Ergebnis speichern\n",
        "output_csv_path = '/content/drive/MyDrive/ie_scripting_datasets/Archive/songs_with_emotions_category.csv'\n",
        "data.to_csv(output_csv_path, index=False)\n",
        "print(f\"Ergebnis gespeichert: {output_csv_path}\")\n"
      ],
      "metadata": {
        "id": "lU2jy3iHwRod",
        "outputId": "96cdeb5d-389f-4f5f-935c-7cfc4e3982ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'category_counts'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'category_counts'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-b97094fff4af>\u001b[0m in \u001b[0;36m<cell line: 41>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m# Spalte hinzufügen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentiment_ratio'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalculate_sentiment_ratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10372\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10373\u001b[0m         )\n\u001b[0;32m> 10374\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"apply\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  10375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10376\u001b[0m     def map(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    914\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m             \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_numba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1079\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m                 \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m                     \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-b97094fff4af>\u001b[0m in \u001b[0;36mcalculate_sentiment_ratio\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# Berechnung der Sentiment-Ratio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalculate_sentiment_ratio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mcategory_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'category_counts'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# String in Dictionary umwandeln\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mpositive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcategory_counts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'positive'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mnegative\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcategory_counts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'negative'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m         \u001b[0;31m# Convert generator to list before going through hashable part\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1236\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1237\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'category_counts'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import ast\n",
        "\n",
        "# Lade die Eingabedatei\n",
        "data = pd.read_csv('/content/drive/MyDrive/ie_scripting_datasets/Archive/processed_songs_without_duplicates.csv')\n",
        "\n",
        "# Lade das NRC Emotion Lexikon\n",
        "nrc_lexicon = pd.read_csv(\n",
        "    '/content/drive/MyDrive/ie_scripting_datasets/Archive/NRC-Emotion-Lexicon-Wordlevel-v0.92.txt',\n",
        "    sep='\\t',\n",
        "    header=None,\n",
        "    names=['word', 'emotion', 'value']\n",
        ")\n",
        "nrc_lexicon = nrc_lexicon[nrc_lexicon['value'] == 1]\n",
        "\n",
        "# Emotionenkategorien\n",
        "emotion_categories = {\n",
        "    'anger': ['anger'],\n",
        "    'fear': ['fear'],\n",
        "    'anticipation': ['anticipation'],\n",
        "    'trust': ['trust'],\n",
        "    'surprise': ['surprise'],\n",
        "    'sadness': ['sadness'],\n",
        "    'joy': ['joy'],\n",
        "    'disgust': ['disgust']\n",
        "}\n",
        "\n",
        "# Funktion zur Emotionenzählung und Kategorisierung\n",
        "def get_emotions_and_category(tokens, lexicon, emotion_categories):\n",
        "    if isinstance(tokens, str):  # Wenn Tokens als String vorliegen\n",
        "        tokens = ast.literal_eval(tokens)  # Konvertiere den String in eine echte Liste\n",
        "\n",
        "    emotions = lexicon[lexicon['word'].isin(tokens)]['emotion'].values\n",
        "    emotion_counts = Counter(emotions)\n",
        "    category_counts = {\n",
        "        category: sum(emotion_counts[emotion] for emotion in emotions_list)\n",
        "        for category, emotions_list in emotion_categories.items()\n",
        "    }\n",
        "    is_positive = category_counts.get('joy', 0) > category_counts.get('sadness', 0)\n",
        "    sentiment = 'positive' if is_positive else 'negative'\n",
        "    return emotion_counts, category_counts, sentiment\n",
        "\n",
        "# Anwenden der Funktion\n",
        "results = data['clean_lyrics'].apply(\n",
        "    lambda x: get_emotions_and_category(x, nrc_lexicon, emotion_categories)\n",
        ")\n",
        "\n",
        "# Ergebnisse extrahieren\n",
        "data['emotion_counts'] = results.map(lambda x: x[0])\n",
        "data['category_counts'] = results.map(lambda x: x[1])\n",
        "data['sentiment'] = results.map(lambda x: x[2])\n",
        "\n",
        "# Sentiment-Ratio berechnen\n",
        "def calculate_sentiment_ratio(row):\n",
        "    # Wenn row['category_counts'] ein String ist, konvertiere es in ein Dictionary\n",
        "    if isinstance(row['category_counts'], str):\n",
        "        category_counts = ast.literal_eval(row['category_counts'])\n",
        "    else:\n",
        "        category_counts = row['category_counts']  # Bereits ein Dictionary\n",
        "\n",
        "    positive = category_counts.get('joy', 0)  # Kategorie \"joy\" als positiv betrachten\n",
        "    negative = category_counts.get('sadness', 0)  # Kategorie \"sadness\" als negativ betrachten\n",
        "\n",
        "    if positive + negative > 0:\n",
        "        return positive / (positive + negative)\n",
        "    return 0\n",
        "\n",
        "data['sentiment_ratio'] = data.apply(calculate_sentiment_ratio, axis=1)\n",
        "\n",
        "\n",
        "# Primäre Emotion bestimmen\n",
        "def determine_primary_emotion(category_counts):\n",
        "    if isinstance(category_counts, str):\n",
        "        category_counts = ast.literal_eval(category_counts)\n",
        "    if not category_counts:\n",
        "        return 'neutral'\n",
        "    primary_emotion = max(category_counts, key=category_counts.get)\n",
        "    if category_counts[primary_emotion] == 0:\n",
        "        return 'neutral'\n",
        "    return primary_emotion\n",
        "data['primary_emotion'] = data['category_counts'].apply(determine_primary_emotion)\n",
        "\n",
        "# Songs nach Emotionen speichern\n",
        "emotion_groups = {\n",
        "    emotion: data[data['primary_emotion'] == emotion]\n",
        "    for emotion in emotion_categories.keys()\n",
        "}\n",
        "for emotion, group in emotion_groups.items():\n",
        "    group.to_csv(f'/content/drive/MyDrive/ie_scripting_datasets/Archive/songs_{emotion}.csv', index=False)\n",
        "\n",
        "# Übersicht ausgeben\n",
        "print(data[['clean_lyrics', 'category_counts', 'primary_emotion']].head())\n",
        "\n",
        "# Gesamtergebnisse speichern\n",
        "output_csv_path = '/content/drive/MyDrive/ie_scripting_datasets/Archive/songs_with_emotions_category.csv'\n",
        "data.to_csv(output_csv_path, index=False)\n",
        "print(f\"Ergebnis gespeichert: {output_csv_path}\")\n"
      ],
      "metadata": {
        "id": "9W37DfEjQgL3",
        "outputId": "8e3a7946-eefa-4594-95dc-a55de439ebe7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                        clean_lyrics  \\\n",
            "0  ['caught', 'ride', 'south', 'dakota', 'two', '...   \n",
            "1  ['make', 'choice', 'never', 'really', 'doubt',...   \n",
            "2  ['instrumental', 'whole', 'world', 'already', ...   \n",
            "3  ['well', 'know', 'house', 'haunted', 'yeah', '...   \n",
            "4  ['take', 'e', 'train', 'babe', 'take', 'easy',...   \n",
            "\n",
            "                                     category_counts primary_emotion  \n",
            "0  {'anger': 0, 'fear': 0, 'anticipation': 0, 'tr...         sadness  \n",
            "1  {'anger': 3, 'fear': 5, 'anticipation': 4, 'tr...            fear  \n",
            "2  {'anger': 1, 'fear': 3, 'anticipation': 6, 'tr...           trust  \n",
            "3  {'anger': 2, 'fear': 7, 'anticipation': 3, 'tr...            fear  \n",
            "4  {'anger': 0, 'fear': 0, 'anticipation': 2, 'tr...    anticipation  \n",
            "Ergebnis gespeichert: /content/drive/MyDrive/ie_scripting_datasets/Archive/songs_with_emotions_category.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Datei laden\n",
        "df = pd.read_csv('/content/drive/MyDrive/ie_scripting_datasets/Archive/songs_with_emotions_category.csv')\n",
        "\n",
        "# Nur die gewünschten Spalten auswählen\n",
        "selected_columns = df[['name', 'artists', 'sentiment', 'primary_emotion']]\n",
        "\n",
        "# Neue Datei speichern\n",
        "selected_columns.to_csv('/content/drive/MyDrive/ie_scripting_datasets/Archive/only_emotions_category.csv.csv', index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "u7_MaMFoD7bZ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eSfhIFRHQfsX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}